# –ë—ã—Å—Ç—Ä–∞—è —Å–ø—Ä–∞–≤–∫–∞ - Ollama + Whisper –Ω–∞ Proxmox

**–î–∞—Ç–∞:** –ù–æ—è–±—Ä—å 8, 2025
**–°—Ç–∞—Ç—É—Å:** ‚úÖ Production Ready

---

## üìç –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –°–µ—Ç—å
- **Proxmox Host:** 192.168.1.124
- **VM 103 (ollama-vm):** 192.168.1.131

### –°–µ—Ä–≤–∏—Å—ã
- **Ollama API:** http://192.168.1.131:11434
- **Whisper API:** http://192.168.1.131:9000

### –†–µ—Å—É—Ä—Å—ã VM
- **CPU:** 4 cores (AMD Ryzen 5 2600)
- **RAM:** 10GB
- **Disk:** 64GB
- **GPU:** NVIDIA P106-100 (6GB VRAM, passthrough)

---

## ü§ñ Ollama

### –ú–æ–¥–µ–ª–∏
```bash
# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://192.168.1.131:11434/api/tags

# –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ:
- llama3.1:8b (4.7GB) - –æ—Å–Ω–æ–≤–Ω–∞—è
- phi3:mini (2.3GB) - —Ä–µ–∑–µ—Ä–≤–Ω–∞—è
```

### –¢–µ—Å—Ç
```bash
# –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
curl http://192.168.1.131:11434/api/generate -d '{
  "model": "llama3.1:8b",
  "prompt": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
  "stream": false
}'

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 35-45 tokens/sec
```

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
```bash
# SSH –≤ VM
ssh gfer@192.168.1.131

# –°—Ç–∞—Ç—É—Å
systemctl status ollama.service

# –õ–æ–≥–∏
journalctl -u ollama.service -f

# GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
watch -n 1 nvidia-smi
```

---

## üé§ Whisper

### API Endpoints
```bash
# Health check
curl http://192.168.1.131:9000/health
# {"status":"ok"}

# –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
curl -X POST http://192.168.1.131:9000/transcribe \
  -F "audio=@file.wav"
# {"text":"..."}
```

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **11 —Å–µ–∫ –∞—É–¥–∏–æ ‚Üí 0.56 —Å–µ–∫** (19x realtime)
- **2.2 —Å–µ–∫ –∞—É–¥–∏–æ ‚Üí 0.44 —Å–µ–∫** (5x realtime)
- **CUDA:** ‚úÖ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
```bash
# –°—Ç–∞—Ç—É—Å
sudo systemctl status whisper-api.service

# –õ–æ–≥–∏
sudo journalctl -u whisper-api.service -f

# –†–µ—Å—Ç–∞—Ä—Ç
sudo systemctl restart whisper-api.service
```

---

## üîß Proxmox VM Management

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ VM 103
```bash
# SSH –≤ Proxmox
ssh root@192.168.1.124

# –°—Ç–∞—Ç—É—Å VM
qm status 103

# –°—Ç–∞—Ä—Ç/–°—Ç–æ–ø
qm start 103
qm stop 103
qm shutdown 103

# –ö–æ–Ω—Ñ–∏–≥
cat /etc/pve/qemu-server/103.conf

# –ö–æ–Ω—Å–æ–ª—å
qm terminal 103
```

### –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å VM
qm shutdown 103

# –ò–∑–º–µ–Ω–∏—Ç—å RAM (–≤ MB)
qm set 103 --memory 12288  # 12GB

# –ó–∞–ø—É—Å—Ç–∏—Ç—å
qm start 103
```

### Backup/Snapshot
```bash
# –°–æ–∑–¥–∞—Ç—å snapshot
qm snapshot 103 before-update

# –°–ø–∏—Å–æ–∫ snapshots
qm listsnapshot 103

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
qm rollback 103 before-update

# Backup
vzdump 103 --mode snapshot --storage local --compress zstd
```

---

## üêõ Troubleshooting

### Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
```bash
ssh gfer@192.168.1.131

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–∏—Å
systemctl status ollama.service

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç
ss -tlnp | grep 11434

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
sudo systemctl restart ollama.service

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU
nvidia-smi
```

### Whisper –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–∏—Å
sudo systemctl status whisper-api.service

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç
sudo ss -tlnp | grep 9000

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
sudo systemctl restart whisper-api.service

# –¢–µ—Å—Ç CLI
cd ~/whisper.cpp
./build/bin/whisper-cli -m models/ggml-base.bin -f samples/jfk.wav
```

### VM –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ù–∞ Proxmox —Ö–æ—Å—Ç–µ
ssh root@192.168.1.124

# –õ–æ–≥–∏ VM
qm status 103
journalctl -xe | grep -i "103"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–º—è—Ç—å —Ö–æ—Å—Ç–∞
free -h

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU binding
lspci -nnk | grep -A 3 nvidia
# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: Kernel driver in use: vfio-pci
```

### GPU –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
```bash
# –í VM
ssh gfer@192.168.1.131

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ GPU –≤–∏–¥–µ–Ω
lspci | grep -i nvidia

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Ollama –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
systemctl show ollama.service | grep CUDA

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Whisper
ldd ~/whisper.cpp/build/bin/whisper-cli | grep cuda
```

---

## üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```text
Telegram Voice (10 —Å–µ–∫)
    ‚Üì
Whisper API (0.5 —Å–µ–∫) ‚Üê GPU
    ‚Üì
llama3.1:8b (2-5 —Å–µ–∫) ‚Üê GPU
    ‚Üì
Telegram Response

–ò—Ç–æ–≥–æ: 3-6 —Å–µ–∫ üöÄ
```

### –ú–µ—Ç—Ä–∏–∫–∏
- **Whisper:** 19x realtime –Ω–∞ GPU
- **Ollama:** 35-45 tok/s –Ω–∞ GPU
- **VRAM:**
  - Ollama: ~5GB
  - Whisper: ~1GB
  - –°–≤–æ–±–æ–¥–Ω–æ: ~0GB (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞ –º–∞–∫—Å–∏–º—É–º)

---

## üîó –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **[OLLAMA-PROXMOX-COMPLETE-GUIDE.md](./OLLAMA-PROXMOX-COMPLETE-GUIDE.md)** - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama + GPU
- **[WHISPER-SETUP.md](./WHISPER-SETUP.md)** - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Whisper
- **[n8n-personal-assistant-ollama-simple.json](./n8n-personal-assistant-ollama-simple.json)** - n8n workflow (ready to import)

---

## ‚úÖ Checklist –¥–ª—è –Ω–æ–≤–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏

### Proxmox —Ö–æ—Å—Ç
- [ ] IOMMU enabled –≤ BIOS
- [ ] GRUB –æ–±–Ω–æ–≤–ª–µ–Ω (`iommu=pt`)
- [ ] VFIO –º–æ–¥—É–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
- [ ] GPU –ø—Ä–∏–≤—è–∑–∞–Ω –∫ vfio-pci

### VM 103
- [ ] Ubuntu 22.04.5 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- [ ] GPU –≤–∏–¥–µ–Ω –≤ VM (`lspci | grep nvidia`)
- [ ] NVIDIA –¥—Ä–∞–π–≤–µ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (`nvidia-smi`)
- [ ] Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∑–∞–ø—É—â–µ–Ω
- [ ] llama3.1:8b –∑–∞–≥—Ä—É–∂–µ–Ω
- [ ] CUDA toolkit —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- [ ] Whisper.cpp —Å–æ–±—Ä–∞–Ω —Å CUDA
- [ ] Whisper API –∑–∞–ø—É—â–µ–Ω

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã
- [ ] `curl http://192.168.1.131:11434/api/tags` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] `curl http://192.168.1.131:9000/health` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] GPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ nvidia-smi
- [ ] Whisper —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∑–∞ < 1 —Å–µ–∫

---

**–í–µ—Ä—Å–∏—è:** 1.0
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** –ù–æ—è–±—Ä—å 8, 2025
**–ê–≤—Ç–æ—Ä:** AI Assistant + Community
